import sys
import optparse
import random
import numpy
from math import log, exp
import os
from collections import Counter
from pprint import pformat
import json
import jenks2
from pprint import pprint as pp
from sklearn import preprocessing
try:
	from shogun.PreProc import SortWordString, SortUlongString
except ImportError:
	from shogun.Preprocessor import SortWordString, SortUlongString
from shogun.Kernel import CommWordStringKernel, CommUlongStringKernel, CombinedKernel, LinearStringKernel, GaussianMatchStringKernel
		
from shogun.Features import StringWordFeatures, StringUlongFeatures, StringCharFeatures, CombinedFeatures, DNA, Labels, RealFeatures
from shogun.Classifier import MSG_INFO, MSG_ERROR

	
from shogun.Classifier import LibSVMOneClass
from shogun.Kernel import CustomKernel, SqrtDiagKernelNormalizer

'''
A program which uses one-class SVM on a single genome to predict genomic islands.

For detailed information, please refer to paper:
LU B, LEONG HW. GI-SVM: A sensitive method for predicting genomic islands based on unannotated sequence of a single genome. Journal of Bioinformatics and Computational Biology. 2016.

Some code is based on kmer-svm (http://kmersvm.beerlab.org/).
'''

################################ k-mer generation #########################################
"""
make a full list of k-mers 

	Arguments:
	kmerlen -- integer, length of k-mer

	Return:
	a list of the full set of k-mers
generate_kmers(6)
"""
def generate_kmers(kmerlen):
	nts = ['A', 'C', 'G', 'T']
	kmers = [] 
	kmers.append('')
	l = 0
	# append one nt once
	while l < kmerlen: 
		imers = [] 
		for imer in kmers:
			for nt in nts: 
				imers.append(imer + nt)
		kmers = imers
		l += 1 
	
	return kmers


def revcomp(seq):
	"""get reverse complement DNA sequence

	Arguments:
	seq -- string, DNA sequence

	Return:
	the reverse complement sequence of the given sequence
	"""
	rc = {'A':'T', 'G':'C', 'C':'G', 'T':'A'}
	rc_str = ''.join([rc[seq[i]] for i in xrange(len(seq) - 1, -1, -1)])
	return rc_str


def generate_rcmap_table(kmerlen, kmers):
	"""make a lookup table for reverse complement k-mer ids for speed 

	Arguments:
	kmerlen -- integer, length of k-mer
	kmers -- list, a full set of k-mers generated by generate_kmers

	Return:
	a dictionary containing the mapping table
	"""
	revcomp_func = revcomp

	kmer_id_dict = {}
	for i in xrange(len(kmers)): 
		kmer_id_dict[kmers[i]] = i

	revcomp_mapping_table = []
	for kmerid in xrange(len(kmers)): 
		rc_id = kmer_id_dict[revcomp_func(kmers[kmerid])]
		if rc_id < kmerid:
			revcomp_mapping_table.append(rc_id)
		# use the smaller id of kmer and its reverse complement to remove redundancy 
		else:
			revcomp_mapping_table.append(kmerid)
				
	return revcomp_mapping_table


# similar as conversion of number systems
def kmerid2kmer(kmerid, kmerlen):
	"""convert integer kmerid to kmer string

	Arguments:
	kmerid -- integer, id of k-mer
	kmerlen -- integer, length of k-mer

	Return:
	kmer string
	"""

	nts = "ACGT"
	kmernts = []
	kmerid2 = kmerid

	for i in xrange(kmerlen):
		ntid = kmerid2 % 4
		kmernts.append(nts[ntid])
		kmerid2 = int((kmerid2 - ntid) / 4)

	return ''.join(reversed(kmernts))


def kmer2kmerid(kmer, kmerlen):
	"""convert kmer string to integer kmerid

	Arguments:
	kmerid -- integer, id of k-mer
	kmerlen -- integer, length of k-mer

	Return:
	id of k-mer
	"""

	nt2id = {'A':0, 'C':1, 'G':2, 'T':3}

	return reduce(lambda x, y: (4 * x + y), [nt2id[x] for x in kmer])


def get_rcmap(kmerid, kmerlen):
	"""mapping kmerid to its reverse complement k-mer on-the-fly

	Arguments:
	kmerid -- integer, id of k-mer
	kmerlen -- integer, length of k-mer

	Return:
	integer kmerid after mapping to its reverse complement
	"""

	# 1. get kmer from kmerid
	# 2. get reverse complement kmer
	# 3. get kmerid from revcomp kmer
	rckmerid = kmer2kmerid(revcomp(kmerid2kmer(kmerid, kmerlen)), kmerlen)

	# use the smaller id of kmer and its reverse complement to remove redundancy
	if rckmerid < kmerid:
		return rckmerid

	return kmerid



################################## sliding window ####################################
'''
return the whole genome as a string
'''
def getGenome(genomefile):  
    genome = ''
    with open(genomefile, 'rb') as fin:
    	# skip the first line
    	fin.next()
        for line in fin:
            genome += line.strip() 

    return genome


'''
Replace ambiguous bases with A 
Keep the replaced file for back up
http://www.boekhoff.info/?pid=data&dat=fasta-codes
'''
def preprocessGenome(genomefile, subs=True):
    genome = ''
    chars = ['A', 'C', 'G', 'T']
    # characters that can be replaced by A, C, G
    a_chars = ['M', 'R', 'W', 'V', 'H', 'D', 'N', 'X']
    c_chars = ['Y', 'S', 'B']
    g_chars = ['K']
    
    outfile = os.path.join(os.path.dirname(genomefile), 'replaced_' + os.path.basename(genomefile))
    fout = open(outfile, 'w')
    
    with open(genomefile, 'rb') as fin:
        # skip the first line
        first_line = fin.readline()

        for line in fin:
            line = line.strip().upper()
            for i, c in enumerate(line):
				if c in a_chars and subs:
					# print c
					fout.write('%s --> A\n' % c)
					line = line[0:i] + 'A' + line[i + 1:]
				elif c in c_chars and subs:
					fout.write('%s --> C\n' % c)
					line = line[0:i] + 'C' + line[i + 1:]
				elif c in g_chars and subs:
					fout.write('%s --> G\n' % c)
					line = line[0:i] + 'G' + line[i + 1:]            	
					                    
            genome += line
   
    fout.close()
    if os.stat(outfile).st_size == 0:
    	os.remove(outfile)
    return genome


"""
Returns a list of sliding windows over the genome
For the last window, make it 5kb to ensure enough k-mers   
"""     
def sliding_window(seq, width=5000, step=2500):   
    seqlen = len(seq)
    windows = []
    sids = []
    # for the last window if != winsize (mostly true), 
	# take different start point to the end of the genome, but again with size=winsize
    for i in range(0, seqlen, step):
    	# last window
        if i + width > seqlen:
        	j = seqlen 
        	i = seqlen - width
        else:
        	j = i + width

        # this is 0-based
        # sids.append((i, j))
        # this is 1-based,
        sids.append((i + 1, j))
        # pos j is not included, use 0-based to extract substr
        slice = seq[i:j].upper()
        windows.append(slice)

        if j == seqlen: break

    return windows, sids
 
 
###################################### spectrum kernel  #################################################
 
# kmerlen is not used here, for consistency when calling ulong feature.
def non_redundant_word_features(feats, kmerlen):
	"""convert the features from Shogun toolbox to non-redundant word features (handle reverse complements)
	Arguments:
	feats -- StringWordFeatures
	kmerlen -- integer, length of k-mer

	Return:
	StringWordFeatures after converting reverse complement k-mer ids
	"""

	rcmap = g_rcmap
	
	# the number of sequences, 1923 for CT18 window size 5000
	print 'The number of feature vectors: %s' % (feats.get_num_vectors())
	
	# one vector for each sequence
	for i in xrange(feats.get_num_vectors()):
		# a list of kmer id for each feature vector
		# some k-mer ids may be redundant
		nf = [rcmap[int(kmerid)] for kmerid in feats.get_feature_vector(i)]

		'''
		set_feature_vector (SGVector< ST > vector, int32_t num)
		'''
		feats.set_feature_vector(numpy.array(nf, numpy.dtype('u2')), i)

	# sort features by kmer id
	preproc = SortWordString()
	preproc.init(feats)
	try:
		feats.add_preproc(preproc)
		feats.apply_preproc()
	except AttributeError:
		feats.add_preprocessor(preproc)
		feats.apply_preprocessor()	
		
	return feats
	

def non_redundant_ulong_features(feats, kmerlen):
	"""convert the features from Shogun toolbox to non-redundant ulong features
	Arguments:
	feats -- StringUlongFeatures
	kmerlen -- integer, length of k-mer

	Return:
	StringUlongFeatures after converting reverse complement k-mer ids
	"""

	for i in xrange(feats.get_num_vectors()):
		nf = [get_rcmap(int(kmerid), kmerlen) \
				for kmerid in feats.get_feature_vector(i)]

		feats.set_feature_vector(numpy.array(nf, numpy.dtype('u8')), i)

	preproc = SortUlongString()
	preproc.init(feats)
	try:
		feats.add_preproc(preproc)
		feats.apply_preproc()
	except AttributeError:
		feats.add_preprocessor(preproc)
		feats.apply_preprocessor()

	return feats


def normal_word_feature(feats):	
	preproc = SortWordString()
	preproc.init(feats)
	feats.add_preprocessor(preproc)
	feats.apply_preprocessor()
	return feats

	
def normal_ulong_feature(feats):	
	preproc = SortUlongString()
	preproc.init(feats)
	feats.add_preprocessor(preproc)
	feats.apply_preprocessor()
	return feats	

   
def _get_spectrum_features(seqs, kmerlen, redundant):
	"""generate spectrum features (internal)

	Arguments:
	seqs -- list of sequences 
	kmerlen -- integer, length of k-mer

	Return:
	StringWord(Ulong)Features after treatment of redundant reverse complement k-mers
	"""

	char_feats = StringCharFeatures(seqs, DNA)

	if kmerlen <= 8:
		string_features = StringWordFeatures
		non_redundant_features = non_redundant_word_features
		normal_features = normal_word_feature
	else:
		string_features = StringUlongFeatures
		non_redundant_features = non_redundant_ulong_features
		normal_features = normal_ulong_feature
	
	feats = string_features(DNA)

	feats.obtain_from_char(char_feats, kmerlen - 1, kmerlen, 0, False)
	
	if redundant:
		print 'Use normal shogun features'
		return normal_features(feats)
	else:
		print 'Use non-redundant features'
		return non_redundant_features(feats, kmerlen)
	
	
def get_char_features(seqs, options):
	feats = StringCharFeatures(seqs, DNA)
		
	feature_vectors = []
	combine_kcount = Counter()
	for i in xrange(feats.get_num_vectors()):
		fv = list(feats.get_feature_vector(i))
		kcount = Counter(fv)
		
# 		output_folder = os.path.join(os.getcwd(), 'char_feature_vector')
# 		if not os.path.exists(output_folder):
# 			os.makedirs(output_folder)		
# 		writeListToFile(os.path.join(output_folder, 'char_feature_vector' + str(i)), kcount.items())
		
		combine_kcount += kcount
		feature_vectors.append(kcount)
		
	#writeListOfTupleToFile('combined_char_feature_vectors', combine_kcount.items())
		
	return feats


def get_spectrum_features(seqs, options):
	"""generate spectrum features (wrapper)
	"""
	return _get_spectrum_features(seqs, options.kmerlen, options.redundant)


def get_weighted_spectrum_features(seqs, options):
	"""generate weighted spectrum features
	"""
	global g_kmers
	global g_rcmap

	subfeats_list = []

	for k in xrange(options.kmerlen, options.kmerlen2 + 1):
		char_feats = StringCharFeatures(seqs, DNA)
		if k <= 8:
			g_kmers = generate_kmers(k)
			g_rcmap = generate_rcmap_table(k, g_kmers)

		subfeats = _get_spectrum_features(seqs, k, options.redundant)
		subfeats_list.append(subfeats)

	return subfeats_list


def get_full_matrix(matrix_file, npos, nneg):
	ltmat = numpy.fromfile(matrix_file, dtype=numpy.float32, sep="\t")

	mat = numpy.zeros((npos + nneg, npos + nneg))

	tril_indices1 = numpy.repeat(xrange(npos + nneg), xrange(1, npos + nneg + 1))
	tril_indices2 = numpy.empty((npos + nneg) * (npos + nneg + 1) / 2, dtype=numpy.int)
	idx = 0
	for i in xrange(1, npos + nneg + 1):
		tril_indices2[idx:(idx + i)] = numpy.arange(i, dtype=numpy.int)
		idx += i

	mat[(tril_indices1, tril_indices2)] = ltmat
	
	# make symmetric mat
	mat.T[(tril_indices1, tril_indices2)] = ltmat

	return mat



def get_spectrum_kernel(feats, options):
	"""build spectrum kernel with non-redundant k-mer list (removing reverse complement)

	Arguments:
	feats -- feature object
	options -- object containing option data 

	Return:
	StringWord(Ulong)Features, CommWord(Ulong)StringKernel
	"""
	if options.kmerlen <= 8:
		return CommWordStringKernel(feats, feats)
	else:
		return CommUlongStringKernel(feats, feats)


def get_wd_kernel(feats, options):
	# build weighted position kernel with non-redundant k-mer list (removing reverse complement)
	return WeightedDegreePositionStringKernel(feats, feats, options.kmerlen)


# Have 'options' as argument to keep consistency	
def get_gaussian_kernel(feats, options):
	dim = feats.get_max_vector_length()	
	width = 1 / (2 * dim)
# 	print 'dim ', dim
# 	print 'width ', width
	width = 0.01
	# dot_feats = RealFeatures(feats)
	return GaussianMatchStringKernel(feats, feats, width)


# Have 'options' as argument to keep consistency	
# Use LinearStringKernel, Computes the standard linear kernel on dense char valued features
def get_linear_kernel(feats, options):
	return LinearStringKernel(feats, feats)
	

def get_weighted_spectrum_kernel(subfeats_list, options):
	"""build weighted spectrum kernel with non-redundant k-mer list (removing reverse complement)

	Arguments:
	subfeats_list -- list of sub-feature objects
	options -- object containing option data 

	Return:
	CombinedFeatures of StringWord(Ulong)Features, CombinedKernel of CommWord(Ulong)StringKernel 
	"""
	kmerlen = options.kmerlen
	kmerlen2 = options.kmerlen2

	subkernels = 0
	kernel = CombinedKernel()
	feats = CombinedFeatures()

	weights = []
	
	i = 0
	for subfeats in subfeats_list:
		feats.append_feature_obj(subfeats)
		
		combine_kcount = Counter()
		for i in xrange(subfeats.get_num_vectors()):
			fv = list(subfeats.get_feature_vector(i))
			combine_kcount += Counter(fv)
			number = len(combine_kcount)
			klen = kmerlen + i
			
	for k in xrange(kmerlen, kmerlen2 + 1):
		if k <= 8:
			subkernel = CommWordStringKernel(10, False) 
		else:
			subkernel = CommUlongStringKernel(10, False)

		kernel.append_kernel(subkernel)
		subkernels += 1

	kernel.init(feats, feats)
	# here the weight for each k-mer is uniform
	'''
	subkernels = 8
	numpy.array([1 / float(subkernels)] * subkernels, numpy.dtype('float64'))
	array([ 0.125,  0.125,  0.125,  0.125,  0.125,  0.125,  0.125,  0.125])
	'''
	kernel.set_subkernel_weights(numpy.array([1 / float(subkernels)] * subkernels, numpy.dtype('float64')))
	
	return kernel


def svm_learn(kernel, options):
	svm = LibSVMOneClass()
			
	if options.quiet == False:
		svm.io.set_loglevel(MSG_INFO)
		svm.io.set_target_to_stderr()

	# use default value of epsilon: 1e-5
	# svm.set_epsilon(options.epsilon)
	svm.parallel.set_num_threads(1)

	svm.set_nu(options.svmNu)
	svm.set_kernel(kernel)
	
	svm.train()

	if options.quiet == False:
		svm.io.set_loglevel(MSG_ERROR)

	return svm


'''
The weighted spetrum kernel use kmer of length between kmerlen and kmerlen2
'''
def runSVM(options, args):
	"""
	set global variable
	"""
	if (options.ktype == 1 or options.ktype == 5 or options.ktype == 6) and (options.kmerlen <= 8):
		global g_kmers
		global g_rcmap

		g_kmers = generate_kmers(options.kmerlen)
		g_rcmap = generate_rcmap_table(options.kmerlen, g_kmers)
	
	
	print 'Read genome sequence.\n'
	genome = preprocessGenome(args[0], options.subs)

	print 'Get sliding window.\n'
	seqs, sids = sliding_window(genome, options.window, options.step)
	print 'Get features and kernel.\n'	

	if options.ktype == 1:
		get_features = get_spectrum_features
		get_kernel = get_spectrum_kernel
	elif options.ktype == 2:
		get_features = get_weighted_spectrum_features
		get_kernel = get_weighted_spectrum_kernel
	elif options.ktype == 3:
		get_features = get_char_features
		get_kernel = get_wd_kernel	
	elif options.ktype == 5:
		get_features = get_char_features
		get_kernel = get_gaussian_kernel	
	elif options.ktype == 6:
		get_features = get_char_features
		get_kernel = get_linear_kernel					
			
	if options.ktype == 4:	
		print 'This is custom kernel.\n'	
		npos = len(sids)
		nneg = 0
		fullmat = get_full_matrix(options.matrixFile, npos, nneg)
		kernel = CustomKernel()
		kernel.set_full_kernel_matrix_from_full(fullmat)
	else:
		feats = get_features(seqs, options)	
		kernel = get_kernel(feats, options)	

	print '\nSVM training.\n'		
	svm = svm_learn(kernel, options)
	
	processSVMOutput(svm, sids, options)	
		
###################################### post processing #############################################
def getRankedResult(oneClassSvm, intervals):
    '''
    the features for weighted spectrum kernel is a list
    to avoid error, use no parameters
    '''
    predictions = oneClassSvm.apply()
	# Distance from hyperplane
    svmRes = predictions.get_values()
    
    lblRes_array = numpy.reshape(predictions.get_labels(), (1, -1))[0]
    # count the number of windows with negative labels
    neg_count = 0
    for lbl in list(lblRes_array):
    	if lbl < 0:
    		neg_count += 1
    print 'The number of windows with negative label is: %d' % neg_count	

    # Normalize the original score to be in the range 0-1
    svmRes_array = numpy.reshape(svmRes, (1, -1))[0]
    min_max_scaler = preprocessing.MinMaxScaler()
    scale_scores = min_max_scaler.fit_transform(svmRes_array)    
    
    #'intervals' is used to record the id and position of each cluster corresponding to the featureSet
    resultDict = zip(intervals, scale_scores)
    rankedResult = sorted(resultDict, key=lambda x: x[1])        

    return rankedResult
 

def getSelectedResultByPercentile(rankedResult, threshold): 
	svmRes_array = []
	for pos, dist in rankedResult:
		svmRes_array.append(dist) 
	# percentile can be [0,100]
	if threshold > 0:
		cutoff = numpy.percentile(svmRes_array, threshold)
	else:
		cutoff = 0
	selectedResult = []
	for (index, value) in rankedResult:        
		if value <= cutoff:
            # do type transformation to facilitate downstream process
			selectedResult.append((int(index[0]), int(index[1]), float(value)))
            
	return selectedResult        
   
              
'''
Get the union of overlapped regions
'''
def merge_score(intervals, options):
    intervals = sorted(intervals, key=lambda x : (int(x[0]), int(x[1])))
    merged_intervals = []
    saved = list(intervals[0])
    
    offset = 1 
    if options.gap:
		offset = 2501		   

    for st, en, score in intervals:  	
        if st - offset <= saved[1]:
            saved[1] = max(saved[1], en)
            # average the score, watch out data format
            saved[2] = (saved[2] + score) / 2
        else:
            # only add the interval to the result when not overlapping with adjacent regions
            yield tuple(saved)
            saved[0] = st
            saved[1] = en
            saved[2] = float(score)
    yield tuple(saved)
 
    
	
############################### output to files ########################################
	 	
def writeListToFile(filename, list):     
    outfile = open(filename, 'w')

    for value in list:
        line = '%s\n' % (str(value))
        outfile.write(line)

    outfile.close()
    
    
def writeListOfTupleToFile(filename, list):     
    outfile = open(filename, 'w')

    for value in list:
        if len(value) == 3:
        	# control the number of precision, avoid too long float
            line = '%s\t%s\t%.3f\n' % (str(value[0]), str(value[1]), float(value[2]))
        else:
        	if type(value[1]) is float:
        		line = '%s\t%.3f\n' % (str(value[0]), str(value[1]))
        	else:
        		line = '%s\t%s\n' % (str(value[0]), str(value[1]))
        outfile.write(line)

    outfile.close()

'''
input: (intervals: (a,b), scale_scores)
'''	
def writeMixedListToFile(filename, list):	 
	outfile = open(filename, 'w')

	for pos, dist in list:
		# control the number of precision, avoid too long float
		line = '%s\t%s\t%.3f\n' % (str(pos[0]), str(pos[1]), float(dist))
		outfile.write(line)

	outfile.close()
	    
'''
read directly from the result list
input format:
30000   40000   -105.612047971 

output format:
FT   misc_feature    14705..20766
FT                   /colour=255 254 254
FT                   /algorithm="alien_hunter"
FT                   /note="threshold: 10.939"
FT                   /score=11.148

write output with scaled score at the same time
'''
def writeEmblFile(filename, regions):
    outfile = filename + '.embl'
    fout = open(outfile, 'w')

    score_list = []
    intervals = []
    for st, en, score in regions:    
		intervals.append((st, en, score))
		score_list.append(score)
            
    mins = min(score_list)
    maxs = max(score_list)
    for st, en, score in intervals:
        # x should be in (0,1), to get different colors
        if maxs - mins != 0:
         	x = (score - mins) / (maxs - mins)
        else:
        	x = score

        green = 255 - (x * 255);
        blue = 255 - (x * 255);
        green = int(green);
        blue = int(blue);
        red = 255;
        color = "%s %s %s" % (red, green, blue)

    
        embl_line = 'FT   misc_feature    %s..%s' % (st, en)
        embl_line += '\nFT                   /colour=%s' % color
        embl_line += '\nFT                   /algorithm="GI-SVM"'
        # float argument required, not str 
        embl_line += '\nFT                   /score=%.2f\n' % (score)
        fout.write(embl_line)         
    fout.close()
    

   
def processSVMOutput(svm, sids, options):
	rankedRes = getRankedResult(svm, sids)
	selectRes = getSelectedResultByPercentile(rankedRes, options.threshold) 

	if options.ktype != 2:
		suffix = '_'.join([str(options.kmerlen), str(options.ktype), str(options.svmNu), str(options.threshold), str(options.window), str(options.step)])
		suffix_rank = '_'.join([str(options.kmerlen), str(options.ktype), str(options.svmNu), '0', str(options.window), str(options.step)])
	elif options.ktype == 2:
		suffix = '_'.join([str(options.kmerlen), str(options.kmerlen2), str(options.ktype), str(options.svmNu), str(options.threshold), str(options.window), str(options.step)])
		suffix_rank = '_'.join([str(options.kmerlen), str(options.kmerlen2), str(options.ktype), str(options.svmNu), '0', str(options.window), str(options.step)])
	if options.redundant:
		suffix += '_r'
	#print suffix	
	#print 'Write output.\n'		
	# The ranking for all the intervals
	print 'Write the ranked list of all the intervals.\n'	
	rank_filepath = os.path.join(options.directory, 'rankedRes_' + suffix_rank)
	# write rankedRes as tab separated to facilitate sorting
	writeMixedListToFile(rank_filepath, rankedRes)
	
	# The intervals above certain thresholds
	print 'Write selected intervals based on the specified cutoff.'
	writeListOfTupleToFile(os.path.join(options.directory, 'selectRes_' + suffix), selectRes)
	
	print 'The number of intevals before merge: %s' % str(len(selectRes)) 
	mergedRes = list(merge_score(selectRes, options))
	print 'The number of intevals after merge: %s' % str(len(mergedRes))
		
	# print out the cutoff value
	print 'Write merged intervals based on the specified cutoff.'
	writeListOfTupleToFile(os.path.join(options.directory, 'mergedRes_' + suffix), mergedRes)  
	
	print 'Write embl format of merged intervals based on the specified cutoff.\n'
	writeEmblFile(os.path.join(options.directory, 'mergedRes_' + suffix), mergedRes)
	
	# use automatic cutoff
	if options.autoCutoff:
		print 'Write selected intervals based on the automatic cutoff.'	
		individualSelectByJenks(rank_filepath)
		
	
##################################### set automatic cutoff ############################################

'''
get intervals and scores separately
'''    
def getRankedIntervals(intervalfile):
    intervals = []
    dists = []
    with open(intervalfile, 'rb') as fin:
        for line in fin:
            # print line
            fields = line.strip().split('\t')
            dist = float(fields[2])

            intervals.append((int(fields[0]), int(fields[1]))) 
            dists.append(dist)
     
    return intervals, dists
   
   
def find(s, ch):
    return [i for i, ltr in enumerate(s) if ltr == ch]
   

'''
Jenks natural breaks optimization
'scores' should be scaled
'''
def jenks(intervals, scores):
    orig_scores = numpy.asarray(scores)
    # scale data to range 0..1
    min_max_scaler = preprocessing.MinMaxScaler()
    scale_scores = min_max_scaler.fit_transform(orig_scores)
    scale_scores_json = json.dumps(list(scale_scores))

    scaled_intervals = zip(intervals, list(scale_scores))
                      
    num_clusters = 3

    # There should be 4 points for 3 clusters
    cutpoints = jenks2.jenks(json.loads(scale_scores_json), num_clusters)

    return scaled_intervals, cutpoints


'''
The automatic threshold is set between cluster2 and cluster3 to get higher recall.
'''
def getSepScore(cutpoints):
    return cutpoints[-2]    
   
 
def getSelectedResultByScore(scaled_intervals, threshold): 
    selectedResult = []

    for pos, dist in scaled_intervals:        
        if dist <= threshold:
            selectedResult.append((int(pos[0]), int(pos[1]), float(dist)))
            
    return selectedResult 
   
             
'''
Find automatic cutoff to select GIs from all the intervals
file: 'rankedRes_*'
'''
def individualSelectByJenks(file):        
        directory = os.path.dirname(os.path.realpath(file))
        # in case the file name contains whole path
        start = os.path.basename(file).index('_') + 1     
        suffix = os.path.basename(file)[start:] 
        '''
        Get 'selectRes_' file name from the suffix, notice the position of cutoff,  e.g. 7_1_0.2_0_5000_2500
        Caveat: current rankedRes_ has cutoff in the filename, not easy to extract cutoff
        '''
        sepIndices = find(suffix, '_')
        # find the last second _ and 3rd _, cutoff may be two digits
        cutoff_index2 = sepIndices[-2]
        cutoff_index1 = sepIndices[-3]
        current_cutoff = suffix[cutoff_index1 + 1:cutoff_index2]

        intervals, dists = getRankedIntervals(file)
        scaled_intervals, cutpoints = jenks(intervals, dists)
        threshold = getSepScore(cutpoints)
        
        print 'The automatic cutoff threshold is: %.3f' % (threshold)
        
        selectRes = getSelectedResultByScore(scaled_intervals, threshold)
               
        # for easy comparison with percentile cutoff, use percentage as file name
        percentage = int(len(selectRes) * 100 / len(intervals))
        new_suffix = suffix[0:cutoff_index1 + 1] + str(percentage) + suffix[cutoff_index2:]            
        # firstly check whether selectRes_ exists or not
        print 'Write selected intervals based on the automatic cutoff.'
        sel_filepath = os.path.join(directory, 'selectRes_auto_' + new_suffix)        
             
        # The intervals above certain thresholds
        writeListOfTupleToFile(sel_filepath, selectRes)

        print 'The number of intevals before merge: %s' % str(len(selectRes)) 
        mergedRes = list(merge_score(selectRes, options))
        print 'The number of intevals after merge: %s' % str(len(mergedRes))
        print 'Write merged intervals based on the automatic cutoff.'
        merge_filepath = os.path.join(directory, 'mergedRes_auto_' + new_suffix)
        writeListOfTupleToFile(merge_filepath, mergedRes)
        print 'Write embl format of merged intervals based on the automatic cutoff.\n'  
        writeEmblFile(merge_filepath, mergedRes)
        
        
                
if __name__ == '__main__':
	usage = "Usage: %prog [options] GENOME_SEQ"
	desc = "Predicting genomic islands via one-class SVM. Steps: 1. take one genome sequence file(FASTA format) as input, 2. train an one-class SVM and get the score"
	parser = optparse.OptionParser(usage=usage, description=desc)
	
	# parameters for svm
	parser.add_option("-t", dest="ktype", type="int", default=1, help="set the type of kernel, 1:Spectrum, 2:Weighted Spectrums (default=1.Spectrum), 3:  Weighted Degree Position String kernel")
	parser.add_option("-N", dest="svmNu", type="float", default=0.1, help="set the parameter nu (default=0.1)")	
# 	parser.add_option("-e", dest="epsilon", type="float", default=0.00001, help="set the precision parameter epsilon (default=0.00001)")
	parser.add_option("-k", dest="kmerlen", type="int", default=6, help="set the (min) length of k-mer for (weighted) spectrum kernel (default = 6)")
	parser.add_option("-K", dest="kmerlen2", type="int", default=8, help="set the max length of k-mer for weighted spectrum kernel (default = 8)")
	parser.add_option("-r", dest="redundant", default=False, action="store_true", help="use original shogun features without considering reverse complement (default=false)")	
	parser.add_option("-s", dest="sort", default=False, action="store_true", help="sort the kmers by absolute values of SVM weights (default=false)")
	# parser.add_option("-l", dest="customKernel", default=False, action="store_true", help="use custom kernel")
	parser.add_option("-m", dest="matrixFile", default='', help="matrix file for custom kernel")		
	
	# parameters for selecting GIs
	parser.add_option("-g", dest="gap", default=False, action="store_true", help="allow to combine adjacent windows if the distance between them is not larger than 2500 bp")
	parser.add_option("-c", "--threshold", dest="threshold", type='int', default=5, help="threshold to keep atypical intervals")
	parser.add_option("-a", "--autoCutoff", dest="autoCutoff", default=False, action="store_true", help="threshold to keep atypical intervals")
	
	# parameters for processing genome
	parser.add_option("-W", dest="window", type="int", default=5000, help="set the size of sliding window (default = 5000)")
	parser.add_option("-S", dest="step", type="int", default=2500, help="set the step size for sliding window (default = 2500)")
	parser.add_option("", "--subs", dest="subs", default=True, action="store_false", help="replace ambiguous codes in fasta sequence file")
	
	parser.add_option("-d", dest="directory", help="set the directory of output files (default=./)")			
	parser.add_option("-q", dest="quiet", default=False, action="store_true", help="supress messages (default=false)")
		
	(options, args) = parser.parse_args()
				
	runSVM(options, args)
	

